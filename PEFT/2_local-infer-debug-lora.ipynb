{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13bdd09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceed.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('../utils')\n",
    "sys.path.append('../templates')\n",
    "\n",
    "from common_lib import check_packages\n",
    "check_packages()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78d58e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import torch\n",
    "import sagemaker, boto3, jinja2\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import serializers, deserializers\n",
    "from peft import AutoPeftModelForCausalLM\n",
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0c4ceb",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1. Local에서 학습한 PEFT 모델을 로드\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "649d81d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24d48406",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_peft_model_dir = output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d077fa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_peft_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cbac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf081c52",
   "metadata": {},
   "source": [
    "### Model 환경설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "456e2383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ea5093e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel, PeftConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d32bc9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2c660600c84058bc3ad22f96f1a32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPTNeoXForCausalLM(\n",
       "      (gpt_neox): GPTNeoXModel(\n",
       "        (embed_in): Embedding(30080, 5120)\n",
       "        (emb_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (layers): ModuleList(\n",
       "          (0-39): 40 x GPTNeoXLayer(\n",
       "            (input_layernorm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "            (post_attention_layernorm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "            (post_attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (post_mlp_dropout): Dropout(p=0.0, inplace=False)\n",
       "            (attention): GPTNeoXAttention(\n",
       "              (rotary_emb): GPTNeoXRotaryEmbedding()\n",
       "              (query_key_value): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=5120, out_features=15360, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=5120, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=15360, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (dense): Linear4bit(in_features=5120, out_features=5120, bias=True)\n",
       "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (mlp): GPTNeoXMLP(\n",
       "              (dense_h_to_4h): Linear4bit(in_features=5120, out_features=20480, bias=True)\n",
       "              (dense_4h_to_h): Linear4bit(in_features=20480, out_features=5120, bias=True)\n",
       "              (act): GELUActivation()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((5120,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (embed_out): Linear(in_features=5120, out_features=30080, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model_id = local_peft_model_dir\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, quantization_config=bnb_config, device_map={\"\":0})\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "model.eval()\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda74072",
   "metadata": {},
   "source": [
    "### 로컬 모델 호출 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8230d6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(x):\n",
    "    q = f\"### 질문: {x}\\n\\n### 답변:\"\n",
    "    # print(q)\n",
    "    gened = model.generate(\n",
    "        **tokenizer(\n",
    "            q, \n",
    "            return_tensors='pt', \n",
    "            return_token_type_ids=False\n",
    "        ).to('cuda'), \n",
    "        max_new_tokens=512,\n",
    "        early_stopping=True,\n",
    "        do_sample=True,\n",
    "        eos_token_id=2,\n",
    "    )\n",
    "    print(tokenizer.decode(gened[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9705329d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 질문: 프로그래밍을 잘하기 위한 세 가지 방법은?\n",
      "\n",
      "### 답변:\n",
      "1. # 연습, 연습, 또 연습: 연습을 하지 않으면 어떤 것도 숙달할 수 없습니다. 좋은 프로그래머가 되기 위해서는 연습이 필수적입니다. 코딩을 하면서 항상 문제를 해결하고, 새로운 문제나 솔루션을 생각하며, 자신이 작성한 코드를 다른 프로그래머에게 보여주는 연습을 하세요. 실력을 향상하기 위해 사용할 수 있는 또 다른 방법은 코딩 경험을 쌓을 수 있는 프로젝트를 작성하는 것입니다. 실제 상황에서 프로그래밍에 참여하여 실제 문제를 만나고, 이를 해결하는 연습을 하세요.2. 코드 정리하기: 소프트웨어 개발은 문제나 이슈가 발생하기 쉬운 매우 난해하고 복잡한 작업입니다. 오류와 누락된 코드를 식별하기 위해 코딩 습관을 모니터링하는 것은 프로그래머의 성공에 매우 중요합니다. 자신의 코드를 정기적으로 검토하고, 오류와 중복 코드를 찾아내고, 필요한 경우 코드를 재작성하는 것을 고려하세요. 모든 소프트웨어 개발은 버그와 에러가 발견될 수 있기에 코드가 효율적이고 정확한지 확인하기 위해 코드를 정기적으로 검토하는 것이 중요합니다.3. 적극적인 학습자가 되십시오: 다른 사람으로부터 배우고, 다른 사람의 코딩을 검토하고, 그 과정에서 스스로에게도 배울 때 진정한 실력을 쌓을 수 있습니다. 새로운 기술과 트렌드에 항상 열려 있어야 하므로, 새로운 코드 작성 방법과 새로운 기술 및 기법을 항상 배우세요. 동료, 선생님 또는 기술을 향상시키는 데 도움이 될 수 있는 다른 사람에게 질문하는 것을 두려워하지 마세요.항상 새로운 문제를 기꺼이 해결하고 다른 사람들로부터 끊임없이 배우기 위해 노력하세요. 이를 통해 최고의 프로그래머가 되기 위한 강력한 기술과 지식을 개발할 수 있습니다.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "gen('프로그래밍을 잘하기 위한 세 가지 방법은?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fdf7ce",
   "metadata": {},
   "source": [
    "## SageMaker Endpoint를 위한 함수 처리 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fb486208",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os.path as osp\n",
    "import json\n",
    "def load_template(template_name: str):\n",
    "    file_name = osp.join(\"../templates\", f\"{template_name}.json\")\n",
    "    if not osp.exists(file_name):\n",
    "        raise ValueError(f\"Can't read {file_name}\")\n",
    "    with open(file_name, encoding='utf-8') as fp:  # 'utf-8' 인코딩으로 파일을 엽니다.\n",
    "        return json.load(fp)\n",
    "\n",
    "\n",
    "def generate_prompt(template, instruction: str, input_text: Union[None, str] = None, label: Union[None, str] = None) -> str:\n",
    "    if input_text:\n",
    "        res = template[\"prompt_input\"].format(instruction=instruction, input=input_text)\n",
    "    else:\n",
    "        res = template[\"prompt_no_input\"].format(instruction=instruction)\n",
    "    if label:\n",
    "        res = f\"{res}{label}\"\n",
    "    return res\n",
    "\n",
    "def get_payload(instruction, input_text, params, template_name=\"kullm\"):\n",
    "    \n",
    "    template = load_template(template_name)\n",
    "    prompt = generate_prompt(template, instruction, input_text)\n",
    "    payload = {\n",
    "        'inputs': prompt,\n",
    "        'parameters': params\n",
    "    }\n",
    "    payload_str = json.dumps(payload)\n",
    "    return payload_str.encode(\"utf-8\")\n",
    "\n",
    "def infer(self, payload, content_type=\"application/json\", verbose=True):\n",
    "    response = self.smr_client.invoke_endpoint(\n",
    "        EndpointName=self.endpoint_name,\n",
    "        ContentType=content_type,\n",
    "        Body=payload\n",
    "    )\n",
    "\n",
    "    res = json.loads(response['Body'].read().decode(\"utf-8\"))\n",
    "    generated_text = res[0][\"generated_text\"]\n",
    "    #generated_text = self.prompter.get_response(generated_text)\n",
    "\n",
    "    generated_text = generated_text.split('###')[0]\n",
    "    if verbose:\n",
    "        pprint.pprint(f'Response: {generated_text}')\n",
    "    return generated_text\n",
    "def parse_response(query_response):\n",
    "    \n",
    "    def traverse(o, tree_types=(list, tuple)):\n",
    "        if isinstance(o, tree_types):\n",
    "            for value in o:\n",
    "                for subvalue in traverse(value, tree_types):\n",
    "                    yield subvalue\n",
    "        else:\n",
    "            yield o\n",
    "\n",
    "    data = eval(query_response)\n",
    "    \n",
    "    listRes = []\n",
    "    for value in traverse(data):\n",
    "        listRes.append(value[\"generated_text\"])\n",
    "        \n",
    "    if len(listRes) >= 2: return listRes\n",
    "    else: return listRes[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bfa99db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"do_sample\": True,\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9,\n",
    "    \"return_full_text\": False,\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"presence_penalty\": None,\n",
    "    \"eos_token_id\": 2,\n",
    "}\n",
    "instruction = \"다음 글을 알기 쉽게 요약해 주세요.\"\n",
    "context = \"\"\"\n",
    "대규모 언어 모델(LLM; Large Language Models) 분야의 발전과 LLM이 가치 있는 인사이트를 제공하는 문제 세트 수가 계속 증가하고 있다는 소식을 들어보셨을 겁니다. \n",
    "대규모 데이터 세트와 여러 작업을 통해 훈련된 대규모 모델은 훈련되지 않은 특정 작업에도 잘 일반화됩니다. 이러한 모델을 파운데이션 모델(foundation model)이라고 하며, 스탠포드 HAI 연구소(Stanford Institute for Human-Centered Artificial Intelligence)에서 처음 대중화한 용어입니다. \n",
    "이러한 파운데이션 모델은 프롬프트 엔지니어링(prompt engineering) 기법의 도움으로 잘 활용할 수 있지만, 유스케이스가 도메인에 매우 특화되어 있거나 작업의 종류가 매우 다양하여 모델을 추가로 커스터마이징해야 하는 경우가 많습니다. \n",
    "특정 도메인이나 작업에 대한 대규모 모델의 성능을 개선하기 위한 한 가지 접근 방식은 더 작은 작업별 데이터 세트로 모델을 추가로 훈련하는 것입니다. 파인 튜닝(fine-tuning)으로 알려진 이 접근 방식은 LLM의 정확도를 성공적으로 개선하지만, 모든 모델 가중치를 수정해야 합니다. \n",
    "파인 튜닝 데이터 세트 크기가 훨씬 작기 때문에 사전 훈련(pre-training)하는 것 보다 훨씬 빠르지만 여전히 상당한 컴퓨팅 성능과 메모리가 필요합니다. \n",
    "파인 튜닝은 원본 모델의 모든 파라미터 가중치를 수정하므로 비용이 많이 들고 원본 모델과 동일한 크기의 모델을 생성하므로 스토리지 용량에도 부담이 됩니다.\n",
    "\"\"\"\n",
    "payload = get_payload(instruction, context, params, \"kullm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "279a2b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.loads(payload.decode('utf-8'))\n",
    "input_prompt, params = data[\"inputs\"], data[\"parameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "63cd0651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inputs': '아래는 작업을 설명하는 명령어와 추가 컨텍스트를 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\\n\\n### 명령어:\\n다음 글을 알기 쉽게 요약해 주세요.\\n\\n### 입력:\\n\\n대규모 언어 모델(LLM; Large Language Models) 분야의 발전과 LLM이 가치 있는 인사이트를 제공하는 문제 세트 수가 계속 증가하고 있다는 소식을 들어보셨을 겁니다. \\n대규모 데이터 세트와 여러 작업을 통해 훈련된 대규모 모델은 훈련되지 않은 특정 작업에도 잘 일반화됩니다. 이러한 모델을 파운데이션 모델(foundation model)이라고 하며, 스탠포드 HAI 연구소(Stanford Institute for Human-Centered Artificial Intelligence)에서 처음 대중화한 용어입니다. \\n이러한 파운데이션 모델은 프롬프트 엔지니어링(prompt engineering) 기법의 도움으로 잘 활용할 수 있지만, 유스케이스가 도메인에 매우 특화되어 있거나 작업의 종류가 매우 다양하여 모델을 추가로 커스터마이징해야 하는 경우가 많습니다. \\n특정 도메인이나 작업에 대한 대규모 모델의 성능을 개선하기 위한 한 가지 접근 방식은 더 작은 작업별 데이터 세트로 모델을 추가로 훈련하는 것입니다. 파인 튜닝(fine-tuning)으로 알려진 이 접근 방식은 LLM의 정확도를 성공적으로 개선하지만, 모든 모델 가중치를 수정해야 합니다. \\n파인 튜닝 데이터 세트 크기가 훨씬 작기 때문에 사전 훈련(pre-training)하는 것 보다 훨씬 빠르지만 여전히 상당한 컴퓨팅 성능과 메모리가 필요합니다. \\n파인 튜닝은 원본 모델의 모든 파라미터 가중치를 수정하므로 비용이 많이 들고 원본 모델과 동일한 크기의 모델을 생성하므로 스토리지 용량에도 부담이 됩니다.\\n\\n\\n### 응답:\\n',\n",
       " 'parameters': {'do_sample': True,\n",
       "  'max_new_tokens': 512,\n",
       "  'temperature': 0.7,\n",
       "  'top_p': 0.9,\n",
       "  'return_full_text': False,\n",
       "  'repetition_penalty': 1.1,\n",
       "  'presence_penalty': None,\n",
       "  'eos_token_id': 2}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0c41890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아래는 작업을 설명하는 명령어와 추가 컨텍스트를 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\\n\\n### 명령어:\\n다음 글을 알기 쉽게 요약해 주세요.\\n\\n### 입력:\\n\\n대규모 언어 모델(LLM; Large Language Models) 분야의 발전과 LLM이 가치 있는 인사이트를 제공하는 문제 세트 수가 계속 증가하고 있다는 소식을 들어보셨을 겁니다. \\n대규모 데이터 세트와 여러 작업을 통해 훈련된 대규모 모델은 훈련되지 않은 특정 작업에도 잘 일반화됩니다. 이러한 모델을 파운데이션 모델(foundation model)이라고 하며, 스탠포드 HAI 연구소(Stanford Institute for Human-Centered Artificial Intelligence)에서 처음 대중화한 용어입니다. \\n이러한 파운데이션 모델은 프롬프트 엔지니어링(prompt engineering) 기법의 도움으로 잘 활용할 수 있지만, 유스케이스가 도메인에 매우 특화되어 있거나 작업의 종류가 매우 다양하여 모델을 추가로 커스터마이징해야 하는 경우가 많습니다. \\n특정 도메인이나 작업에 대한 대규모 모델의 성능을 개선하기 위한 한 가지 접근 방식은 더 작은 작업별 데이터 세트로 모델을 추가로 훈련하는 것입니다. 파인 튜닝(fine-tuning)으로 알려진 이 접근 방식은 LLM의 정확도를 성공적으로 개선하지만, 모든 모델 가중치를 수정해야 합니다. \\n파인 튜닝 데이터 세트 크기가 훨씬 작기 때문에 사전 훈련(pre-training)하는 것 보다 훨씬 빠르지만 여전히 상당한 컴퓨팅 성능과 메모리가 필요합니다. \\n파인 튜닝은 원본 모델의 모든 파라미터 가중치를 수정하므로 비용이 많이 들고 원본 모델과 동일한 크기의 모델을 생성하므로 스토리지 용량에도 부담이 됩니다.\\n\\n\\n### 응답:\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d876032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "result = model.generate(\n",
    "        **tokenizer(\n",
    "            input_prompt, \n",
    "            return_tensors='pt', \n",
    "            return_token_type_ids=False\n",
    "        ).to('cuda'), \n",
    "        max_new_tokens=512,\n",
    "        early_stopping=True,\n",
    "        do_sample=True,\n",
    "        eos_token_id=2,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "533f0b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decode_output :  아래는 작업을 설명하는 명령어와 추가 컨텍스트를 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\n",
      "\n",
      "### 명령어:\n",
      "다음 글을 알기 쉽게 요약해 주세요.\n",
      "\n",
      "### 입력:\n",
      "\n",
      "대규모 언어 모델(LLM; Large Language Models) 분야의 발전과 LLM이 가치 있는 인사이트를 제공하는 문제 세트 수가 계속 증가하고 있다는 소식을 들어보셨을 겁니다. \n",
      "대규모 데이터 세트와 여러 작업을 통해 훈련된 대규모 모델은 훈련되지 않은 특정 작업에도 잘 일반화됩니다. 이러한 모델을 파운데이션 모델(foundation model)이라고 하며, 스탠포드 HAI 연구소(Stanford Institute for Human-Centered Artificial Intelligence)에서 처음 대중화한 용어입니다. \n",
      "이러한 파운데이션 모델은 프롬프트 엔지니어링(prompt engineering) 기법의 도움으로 잘 활용할 수 있지만, 유스케이스가 도메인에 매우 특화되어 있거나 작업의 종류가 매우 다양하여 모델을 추가로 커스터마이징해야 하는 경우가 많습니다. \n",
      "특정 도메인이나 작업에 대한 대규모 모델의 성능을 개선하기 위한 한 가지 접근 방식은 더 작은 작업별 데이터 세트로 모델을 추가로 훈련하는 것입니다. 파인 튜닝(fine-tuning)으로 알려진 이 접근 방식은 LLM의 정확도를 성공적으로 개선하지만, 모든 모델 가중치를 수정해야 합니다. \n",
      "파인 튜닝 데이터 세트 크기가 훨씬 작기 때문에 사전 훈련(pre-training)하는 것 보다 훨씬 빠르지만 여전히 상당한 컴퓨팅 성능과 메모리가 필요합니다. \n",
      "파인 튜닝은 원본 모델의 모든 파라미터 가중치를 수정하므로 비용이 많이 들고 원본 모델과 동일한 크기의 모델을 생성하므로 스토리지 용량에도 부담이 됩니다.\n",
      "\n",
      "\n",
      "### 응답:\n",
      "LLM 분야의 발전과 함께 특정 작업이나 도메인에 대한 대규모 모델의 정확도를 개선하기 위해 파운데이션 모델과 파인튜닝 사이의 절충안이 제시되었습니다. 파인 튜닝 알고리즘을 이용하여 모델 학습 과정에서 일부 가중치와 특징을 추가로 수정할 수 있지만, 사전 훈련 과정보다 훨씬 빠르고 컴퓨팅 리소스와 메모리의 부담이 있습니다. 파운데이션 모델은 특정 작업에 대해 우수한 일반화를 제공하지만, 프롬프트 엔지니어링 기법이나 파인 튜닝 기법이 필요한 경우가 많습니다.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "#print(tokenizer.decode(result[0]))\n",
    "#print(result)\n",
    "\n",
    "decoded_output = tokenizer.decode(result[0])\n",
    "\n",
    "print(\"decode_output : \", decoded_output)\n",
    "# 이제 JSON 형식으로 변환\n",
    "json_data = json.dumps({\"generated_text\": decoded_output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2b339655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"generated_text\": \"\\\\uc544\\\\ub798\\\\ub294 \\\\uc791\\\\uc5c5\\\\uc744 \\\\uc124\\\\uba85\\\\ud558\\\\ub294 \\\\uba85\\\\ub839\\\\uc5b4\\\\uc640 \\\\ucd94\\\\uac00 \\\\ucee8\\\\ud14d\\\\uc2a4\\\\ud2b8\\\\ub97c \\\\uc81c\\\\uacf5\\\\ud558\\\\ub294 \\\\uc785\\\\ub825\\\\uc774 \\\\uc9dd\\\\uc744 \\\\uc774\\\\ub8e8\\\\ub294 \\\\uc608\\\\uc81c\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\uc694\\\\uccad\\\\uc744 \\\\uc801\\\\uc808\\\\ud788 \\\\uc644\\\\ub8cc\\\\ud558\\\\ub294 \\\\uc751\\\\ub2f5\\\\uc744 \\\\uc791\\\\uc131\\\\ud558\\\\uc138\\\\uc694.\\\\n\\\\n### \\\\uba85\\\\ub839\\\\uc5b4:\\\\n\\\\ub2e4\\\\uc74c \\\\uae00\\\\uc744 \\\\uc54c\\\\uae30 \\\\uc27d\\\\uac8c \\\\uc694\\\\uc57d\\\\ud574 \\\\uc8fc\\\\uc138\\\\uc694.\\\\n\\\\n### \\\\uc785\\\\ub825:\\\\n\\\\n\\\\ub300\\\\uaddc\\\\ubaa8 \\\\uc5b8\\\\uc5b4 \\\\ubaa8\\\\ub378(LLM; Large Language Models) \\\\ubd84\\\\uc57c\\\\uc758 \\\\ubc1c\\\\uc804\\\\uacfc LLM\\\\uc774 \\\\uac00\\\\uce58 \\\\uc788\\\\ub294 \\\\uc778\\\\uc0ac\\\\uc774\\\\ud2b8\\\\ub97c \\\\uc81c\\\\uacf5\\\\ud558\\\\ub294 \\\\ubb38\\\\uc81c \\\\uc138\\\\ud2b8 \\\\uc218\\\\uac00 \\\\uacc4\\\\uc18d \\\\uc99d\\\\uac00\\\\ud558\\\\uace0 \\\\uc788\\\\ub2e4\\\\ub294 \\\\uc18c\\\\uc2dd\\\\uc744 \\\\ub4e4\\\\uc5b4\\\\ubcf4\\\\uc168\\\\uc744 \\\\uac81\\\\ub2c8\\\\ub2e4. \\\\n\\\\ub300\\\\uaddc\\\\ubaa8 \\\\ub370\\\\uc774\\\\ud130 \\\\uc138\\\\ud2b8\\\\uc640 \\\\uc5ec\\\\ub7ec \\\\uc791\\\\uc5c5\\\\uc744 \\\\ud1b5\\\\ud574 \\\\ud6c8\\\\ub828\\\\ub41c \\\\ub300\\\\uaddc\\\\ubaa8 \\\\ubaa8\\\\ub378\\\\uc740 \\\\ud6c8\\\\ub828\\\\ub418\\\\uc9c0 \\\\uc54a\\\\uc740 \\\\ud2b9\\\\uc815 \\\\uc791\\\\uc5c5\\\\uc5d0\\\\ub3c4 \\\\uc798 \\\\uc77c\\\\ubc18\\\\ud654\\\\ub429\\\\ub2c8\\\\ub2e4. \\\\uc774\\\\ub7ec\\\\ud55c \\\\ubaa8\\\\ub378\\\\uc744 \\\\ud30c\\\\uc6b4\\\\ub370\\\\uc774\\\\uc158 \\\\ubaa8\\\\ub378(foundation model)\\\\uc774\\\\ub77c\\\\uace0 \\\\ud558\\\\uba70, \\\\uc2a4\\\\ud0e0\\\\ud3ec\\\\ub4dc HAI \\\\uc5f0\\\\uad6c\\\\uc18c(Stanford Institute for Human-Centered Artificial Intelligence)\\\\uc5d0\\\\uc11c \\\\ucc98\\\\uc74c \\\\ub300\\\\uc911\\\\ud654\\\\ud55c \\\\uc6a9\\\\uc5b4\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\n\\\\uc774\\\\ub7ec\\\\ud55c \\\\ud30c\\\\uc6b4\\\\ub370\\\\uc774\\\\uc158 \\\\ubaa8\\\\ub378\\\\uc740 \\\\ud504\\\\ub86c\\\\ud504\\\\ud2b8 \\\\uc5d4\\\\uc9c0\\\\ub2c8\\\\uc5b4\\\\ub9c1(prompt engineering) \\\\uae30\\\\ubc95\\\\uc758 \\\\ub3c4\\\\uc6c0\\\\uc73c\\\\ub85c \\\\uc798 \\\\ud65c\\\\uc6a9\\\\ud560 \\\\uc218 \\\\uc788\\\\uc9c0\\\\ub9cc, \\\\uc720\\\\uc2a4\\\\ucf00\\\\uc774\\\\uc2a4\\\\uac00 \\\\ub3c4\\\\uba54\\\\uc778\\\\uc5d0 \\\\ub9e4\\\\uc6b0 \\\\ud2b9\\\\ud654\\\\ub418\\\\uc5b4 \\\\uc788\\\\uac70\\\\ub098 \\\\uc791\\\\uc5c5\\\\uc758 \\\\uc885\\\\ub958\\\\uac00 \\\\ub9e4\\\\uc6b0 \\\\ub2e4\\\\uc591\\\\ud558\\\\uc5ec \\\\ubaa8\\\\ub378\\\\uc744 \\\\ucd94\\\\uac00\\\\ub85c \\\\ucee4\\\\uc2a4\\\\ud130\\\\ub9c8\\\\uc774\\\\uc9d5\\\\ud574\\\\uc57c \\\\ud558\\\\ub294 \\\\uacbd\\\\uc6b0\\\\uac00 \\\\ub9ce\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\n\\\\ud2b9\\\\uc815 \\\\ub3c4\\\\uba54\\\\uc778\\\\uc774\\\\ub098 \\\\uc791\\\\uc5c5\\\\uc5d0 \\\\ub300\\\\ud55c \\\\ub300\\\\uaddc\\\\ubaa8 \\\\ubaa8\\\\ub378\\\\uc758 \\\\uc131\\\\ub2a5\\\\uc744 \\\\uac1c\\\\uc120\\\\ud558\\\\uae30 \\\\uc704\\\\ud55c \\\\ud55c \\\\uac00\\\\uc9c0 \\\\uc811\\\\uadfc \\\\ubc29\\\\uc2dd\\\\uc740 \\\\ub354 \\\\uc791\\\\uc740 \\\\uc791\\\\uc5c5\\\\ubcc4 \\\\ub370\\\\uc774\\\\ud130 \\\\uc138\\\\ud2b8\\\\ub85c \\\\ubaa8\\\\ub378\\\\uc744 \\\\ucd94\\\\uac00\\\\ub85c \\\\ud6c8\\\\ub828\\\\ud558\\\\ub294 \\\\uac83\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\ud30c\\\\uc778 \\\\ud29c\\\\ub2dd(fine-tuning)\\\\uc73c\\\\ub85c \\\\uc54c\\\\ub824\\\\uc9c4 \\\\uc774 \\\\uc811\\\\uadfc \\\\ubc29\\\\uc2dd\\\\uc740 LLM\\\\uc758 \\\\uc815\\\\ud655\\\\ub3c4\\\\ub97c \\\\uc131\\\\uacf5\\\\uc801\\\\uc73c\\\\ub85c \\\\uac1c\\\\uc120\\\\ud558\\\\uc9c0\\\\ub9cc, \\\\ubaa8\\\\ub4e0 \\\\ubaa8\\\\ub378 \\\\uac00\\\\uc911\\\\uce58\\\\ub97c \\\\uc218\\\\uc815\\\\ud574\\\\uc57c \\\\ud569\\\\ub2c8\\\\ub2e4. \\\\n\\\\ud30c\\\\uc778 \\\\ud29c\\\\ub2dd \\\\ub370\\\\uc774\\\\ud130 \\\\uc138\\\\ud2b8 \\\\ud06c\\\\uae30\\\\uac00 \\\\ud6e8\\\\uc52c \\\\uc791\\\\uae30 \\\\ub54c\\\\ubb38\\\\uc5d0 \\\\uc0ac\\\\uc804 \\\\ud6c8\\\\ub828(pre-training)\\\\ud558\\\\ub294 \\\\uac83 \\\\ubcf4\\\\ub2e4 \\\\ud6e8\\\\uc52c \\\\ube60\\\\ub974\\\\uc9c0\\\\ub9cc \\\\uc5ec\\\\uc804\\\\ud788 \\\\uc0c1\\\\ub2f9\\\\ud55c \\\\ucef4\\\\ud4e8\\\\ud305 \\\\uc131\\\\ub2a5\\\\uacfc \\\\uba54\\\\ubaa8\\\\ub9ac\\\\uac00 \\\\ud544\\\\uc694\\\\ud569\\\\ub2c8\\\\ub2e4. \\\\n\\\\ud30c\\\\uc778 \\\\ud29c\\\\ub2dd\\\\uc740 \\\\uc6d0\\\\ubcf8 \\\\ubaa8\\\\ub378\\\\uc758 \\\\ubaa8\\\\ub4e0 \\\\ud30c\\\\ub77c\\\\ubbf8\\\\ud130 \\\\uac00\\\\uc911\\\\uce58\\\\ub97c \\\\uc218\\\\uc815\\\\ud558\\\\ubbc0\\\\ub85c \\\\ube44\\\\uc6a9\\\\uc774 \\\\ub9ce\\\\uc774 \\\\ub4e4\\\\uace0 \\\\uc6d0\\\\ubcf8 \\\\ubaa8\\\\ub378\\\\uacfc \\\\ub3d9\\\\uc77c\\\\ud55c \\\\ud06c\\\\uae30\\\\uc758 \\\\ubaa8\\\\ub378\\\\uc744 \\\\uc0dd\\\\uc131\\\\ud558\\\\ubbc0\\\\ub85c \\\\uc2a4\\\\ud1a0\\\\ub9ac\\\\uc9c0 \\\\uc6a9\\\\ub7c9\\\\uc5d0\\\\ub3c4 \\\\ubd80\\\\ub2f4\\\\uc774 \\\\ub429\\\\ub2c8\\\\ub2e4.\\\\n\\\\n\\\\n### \\\\uc751\\\\ub2f5:\\\\nLLM \\\\ubd84\\\\uc57c\\\\uc758 \\\\ubc1c\\\\uc804\\\\uacfc \\\\ud568\\\\uaed8 \\\\ud2b9\\\\uc815 \\\\uc791\\\\uc5c5\\\\uc774\\\\ub098 \\\\ub3c4\\\\uba54\\\\uc778\\\\uc5d0 \\\\ub300\\\\ud55c \\\\ub300\\\\uaddc\\\\ubaa8 \\\\ubaa8\\\\ub378\\\\uc758 \\\\uc815\\\\ud655\\\\ub3c4\\\\ub97c \\\\uac1c\\\\uc120\\\\ud558\\\\uae30 \\\\uc704\\\\ud574 \\\\ud30c\\\\uc6b4\\\\ub370\\\\uc774\\\\uc158 \\\\ubaa8\\\\ub378\\\\uacfc \\\\ud30c\\\\uc778\\\\ud29c\\\\ub2dd \\\\uc0ac\\\\uc774\\\\uc758 \\\\uc808\\\\ucda9\\\\uc548\\\\uc774 \\\\uc81c\\\\uc2dc\\\\ub418\\\\uc5c8\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\ud30c\\\\uc778 \\\\ud29c\\\\ub2dd \\\\uc54c\\\\uace0\\\\ub9ac\\\\uc998\\\\uc744 \\\\uc774\\\\uc6a9\\\\ud558\\\\uc5ec \\\\ubaa8\\\\ub378 \\\\ud559\\\\uc2b5 \\\\uacfc\\\\uc815\\\\uc5d0\\\\uc11c \\\\uc77c\\\\ubd80 \\\\uac00\\\\uc911\\\\uce58\\\\uc640 \\\\ud2b9\\\\uc9d5\\\\uc744 \\\\ucd94\\\\uac00\\\\ub85c \\\\uc218\\\\uc815\\\\ud560 \\\\uc218 \\\\uc788\\\\uc9c0\\\\ub9cc, \\\\uc0ac\\\\uc804 \\\\ud6c8\\\\ub828 \\\\uacfc\\\\uc815\\\\ubcf4\\\\ub2e4 \\\\ud6e8\\\\uc52c \\\\ube60\\\\ub974\\\\uace0 \\\\ucef4\\\\ud4e8\\\\ud305 \\\\ub9ac\\\\uc18c\\\\uc2a4\\\\uc640 \\\\uba54\\\\ubaa8\\\\ub9ac\\\\uc758 \\\\ubd80\\\\ub2f4\\\\uc774 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\ud30c\\\\uc6b4\\\\ub370\\\\uc774\\\\uc158 \\\\ubaa8\\\\ub378\\\\uc740 \\\\ud2b9\\\\uc815 \\\\uc791\\\\uc5c5\\\\uc5d0 \\\\ub300\\\\ud574 \\\\uc6b0\\\\uc218\\\\ud55c \\\\uc77c\\\\ubc18\\\\ud654\\\\ub97c \\\\uc81c\\\\uacf5\\\\ud558\\\\uc9c0\\\\ub9cc, \\\\ud504\\\\ub86c\\\\ud504\\\\ud2b8 \\\\uc5d4\\\\uc9c0\\\\ub2c8\\\\uc5b4\\\\ub9c1 \\\\uae30\\\\ubc95\\\\uc774\\\\ub098 \\\\ud30c\\\\uc778 \\\\ud29c\\\\ub2dd \\\\uae30\\\\ubc95\\\\uc774 \\\\ud544\\\\uc694\\\\ud55c \\\\uacbd\\\\uc6b0\\\\uac00 \\\\ub9ce\\\\uc2b5\\\\ub2c8\\\\ub2e4.<|endoftext|>\"}'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "eb00a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_text = parse_response(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "873b20ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아래는 작업을 설명하는 명령어와 추가 컨텍스트를 제공하는 입력이 짝을 이루는 예제입니다. 요청을 적절히 완료하는 응답을 작성하세요.\\n\\n### 명령어:\\n다음 글을 알기 쉽게 요약해 주세요.\\n\\n### 입력:\\n\\n대규모 언어 모델(LLM; Large Language Models) 분야의 발전과 LLM이 가치 있는 인사이트를 제공하는 문제 세트 수가 계속 증가하고 있다는 소식을 들어보셨을 겁니다. \\n대규모 데이터 세트와 여러 작업을 통해 훈련된 대규모 모델은 훈련되지 않은 특정 작업에도 잘 일반화됩니다. 이러한 모델을 파운데이션 모델(foundation model)이라고 하며, 스탠포드 HAI 연구소(Stanford Institute for Human-Centered Artificial Intelligence)에서 처음 대중화한 용어입니다. \\n이러한 파운데이션 모델은 프롬프트 엔지니어링(prompt engineering) 기법의 도움으로 잘 활용할 수 있지만, 유스케이스가 도메인에 매우 특화되어 있거나 작업의 종류가 매우 다양하여 모델을 추가로 커스터마이징해야 하는 경우가 많습니다. \\n특정 도메인이나 작업에 대한 대규모 모델의 성능을 개선하기 위한 한 가지 접근 방식은 더 작은 작업별 데이터 세트로 모델을 추가로 훈련하는 것입니다. 파인 튜닝(fine-tuning)으로 알려진 이 접근 방식은 LLM의 정확도를 성공적으로 개선하지만, 모든 모델 가중치를 수정해야 합니다. \\n파인 튜닝 데이터 세트 크기가 훨씬 작기 때문에 사전 훈련(pre-training)하는 것 보다 훨씬 빠르지만 여전히 상당한 컴퓨팅 성능과 메모리가 필요합니다. \\n파인 튜닝은 원본 모델의 모든 파라미터 가중치를 수정하므로 비용이 많이 들고 원본 모델과 동일한 크기의 모델을 생성하므로 스토리지 용량에도 부담이 됩니다.\\n\\n\\n### 응답:\\nLLM 분야의 발전과 함께 특정 작업이나 도메인에 대한 대규모 모델의 정확도를 개선하기 위해 파운데이션 모델과 파인튜닝 사이의 절충안이 제시되었습니다. 파인 튜닝 알고리즘을 이용하여 모델 학습 과정에서 일부 가중치와 특징을 추가로 수정할 수 있지만, 사전 훈련 과정보다 훨씬 빠르고 컴퓨팅 리소스와 메모리의 부담이 있습니다. 파운데이션 모델은 특정 작업에 대해 우수한 일반화를 제공하지만, 프롬프트 엔지니어링 기법이나 파인 튜닝 기법이 필요한 경우가 많습니다.<|endoftext|>'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "90cafbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM 분야의 발전과 함께 특정 작업이나 도메인에 대한 대규모 모델의 정확도를 개선하기 위해 파운데이션 모델과 파인튜닝 사이의 절충안이 제시되었습니다. 파인 튜닝 알고리즘을 이용하여 모델 학습 과정에서 일부 가중치와 특징을 추가로 수정할 수 있지만, 사전 훈련 과정보다 훨씬 빠르고 컴퓨팅 리소스와 메모리의 부담이 있습니다. 파운데이션 모델은 특정 작업에 대해 우수한 일반화를 제공하지만, 프롬프트 엔지니어링 기법이나 파인 튜닝 기법이 필요한 경우가 많습니다.<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "parts = generated_text.split('### 응답:')\n",
    "\n",
    "# parts의 길이가 2 이상이면, '### 응답:' 이후의 부분을 추출합니다.\n",
    "if len(parts) >= 2:\n",
    "    response_text = parts[1]\n",
    "else:\n",
    "    response_text = \"\"  # '### 응답:'이 없는 경우 빈 문자열을 반환합니다.\n",
    "\n",
    "print(response_text.strip())  # 앞뒤 공백을 제거하고 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b101d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
